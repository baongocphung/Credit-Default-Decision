---
title: "QRM2- Machine Learning"
author: "Group 2"
date: "2025-10-25"
---
## Data setup
```{r}
library(readr)
pd <- read.csv("D:/loan.csv")
head(pd)
```
## Data summary
```{r}
dim(pd)
summary(pd)
```
# Step 1. Data Cleaning
## Check duplicate values
```{r}
#sum(duplicated(pd))
```
## Missing summary
```{r}
library(dplyr)
missing_summary <- data.frame(
  variable = names(pd),
  missing_count = colSums(is.na(pd)),
  missing_percent = round(colMeans(is.na(pd)) * 100, 2)
) %>%
  arrange(desc(missing_percent))
print(missing_summary)
```
## Delete missing variables (missing values > 90%)
```{r}
library(dplyr)
library(tidyverse)

pd <- pd %>% select(-id, -member_id, -url,
-orig_projected_additional_accrued_interest, -hardship_amount,-hardship_dpd, -hardship_loan_status, -deferral_term, -hardship_end_date, -hardship_status, -hardship_start_date, -hardship_reason, -hardship_type, -hardship_payoff_balance_amount, -hardship_last_payment_amount, -hardship_length, -payment_plan_start_date, -debt_settlement_flag_date, -settlement_term, -settlement_amount, -settlement_date, -settlement_percentage, -settlement_status, -sec_app_mths_since_last_major_derog, -sec_app_revol_util, -revol_bal_joint, -sec_app_earliest_cr_line, -sec_app_mort_acc, -sec_app_open_act_il, -sec_app_num_rev_accts, -sec_app_inq_last_6mths, -sec_app_chargeoff_within_12_mths, -sec_app_open_acc, -sec_app_collections_12_mths_ex_med, -verification_status_joint, -dti_joint, -annual_inc_joint, -desc)
```
## Delete some ineffective/leakage variables
```{r}
library(dplyr)
library(tidyverse)

pd <- pd %>% 
  select(-emp_title,-title,-zip_code,-policy_code,-out_prncp_inv,-total_pymnt_inv,-recoveries,-last_pymnt_d,-last_pymnt_amnt)

pd <- pd %>% select(-out_prncp,-total_pymnt,-total_rec_prncp,-total_rec_int,-total_rec_late_fee,-collection_recovery_fee,-debt_settlement_flag,-hardship_flag,next_pymnt_d,-chargeoff_within_12_mths,-delinq_amnt,-acc_now_delinq,-num_tl_120dpd_2m,-num_tl_30dpd)
```
## Target variable (loan_status)
```{r}
library(dplyr)
unique(pd$loan_status)
pd <- pd %>%
  mutate(loan_status = case_when(
    #Good loans (0) - NOT DEFAULT
    loan_status %in% c("Fully Paid", 
                       "Current", 
                       "In Grace Period", 
                       "Does not meet the credit policy. Status:Fully Paid") ~ 0,
    
    #Bad loans (1) - DEFAULT
    loan_status %in% c("Charged Off", 
                       "Late (31-120 days)", 
                       "Late (16-30 days)", 
                       "Does not meet the credit policy. Status:Charged Off", 
                       "Default") ~ 1,
    
    TRUE ~ NA_real_
  ))

#Verify
table(pd$loan_status, useNA = "ifany")
prop.table(table(pd$loan_status)) * 100
```
## Split data
```{r}
library(caret)

pd$loan_status <- as.factor(pd$loan_status)
set.seed(123)

train_index <- createDataPartition(
  y = pd$loan_status,        
  p = 0.8,               
  list = FALSE,          
  times = 1              
)

train_pd <- pd[train_index, ]
test_pd <- pd[-train_index, ]

prop.table(table(pd$loan_status))
prop.table(table(train_pd$loan_status))
prop.table(table(test_pd$loan_status))
```
## Fill missing values (missing values < 10%)
```{r}
library(purrr)

#Calculate missing_summary from train set only
missing_summary_train <- train_pd %>%
  summarise(across(everything(), 
                   ~sum(is.na(.)) / length(.) * 100)) %>%
  pivot_longer(everything(), 
               names_to = "variable", 
               values_to = "missing_percent")

# Create getmode function
getmode <- function(v) {
  v <- v[!is.na(v)]  
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]
}

# Filter variables with < 10% missing
cols_to_impute <- missing_summary_train %>%
  filter(missing_percent > 0 & missing_percent < 10) %>%
  pull(variable)

cols_to_median <- cols_to_impute[sapply(train_pd[cols_to_impute], is.numeric)]

cols_to_mode <- cols_to_impute[sapply(train_pd[cols_to_impute], is.character)]

# Calculate median/mode of train set
medians_train <- map_dbl(train_pd[cols_to_median], 
                         ~median(., na.rm = TRUE))
modes_train <- map_chr(train_pd[cols_to_mode], 
                       ~getmode(.))

# Apply to train set
train_pd <- train_pd %>%
  mutate(across(all_of(cols_to_median), 
                ~coalesce(., medians_train[cur_column()]))) %>%
  mutate(across(all_of(cols_to_mode), 
                ~coalesce(., modes_train[cur_column()])))

# Apply to test set (use same values with train)
test_pd <- test_pd %>%
  mutate(across(all_of(cols_to_median), 
                ~coalesce(., medians_train[cur_column()]))) %>%
  mutate(across(all_of(cols_to_mode), 
                ~coalesce(., modes_train[cur_column()])))
```
## Fill by Unknown/Arbitrary value (90% > missing values > 10%)
```{r}
library(dplyr)
library(tidyr)

# Filter variables with > 10% missing
cols_high_missing <- missing_summary_train %>%
  filter(missing_percent > 10) %>%
  pull(variable)

# Fill by "unknown" (character/factor)
## Filter character/factor columns
cols_high_missing_character <- cols_high_missing[
  sapply(train_pd[cols_high_missing], 
         function(x) is.character(x) | is.factor(x))
]

## Apply "unknown" to BOTH train and test
train_pd <- train_pd %>%
  mutate(across(all_of(cols_high_missing_character), 
                ~replace_na(., "unknown")))

test_pd <- test_pd %>%
  mutate(across(all_of(cols_high_missing_character), 
                ~replace_na(., "unknown")))


# Fill by -99999 (numeric)
## Filter numeric columns with high missing
cols_high_missing_numeric <- cols_high_missing[
  sapply(train_pd[cols_high_missing], is.numeric)
]

## Apply -99999 to BOTH train and test
train_pd <- train_pd %>%
  mutate(across(all_of(cols_high_missing_numeric), 
                ~replace_na(., -99999)))

test_pd <- test_pd %>%
  mutate(across(all_of(cols_high_missing_numeric), 
                ~replace_na(., -99999)))
```
## Save file
```{r}
library
write_csv(test_pd, "test_pd.csv")
write_csv(train_pd, "train_pd.csv")
```
# Step 2. Feature Engineering & Encoding
## Data setup
```{r}
library(readr)
train_pd <- read_csv("D:/train_pd.csv")
test_pd <- read_csv("D:/test_pd.csv")
head(train_pd)
head(test_pd)
```
## Logical check (Check if some obs false of logic => Delete)
```{r}
library(dplyr)

#Check if funded_amnt > loan_amnt => Delete if yes
pd %>% 
  filter(funded_amnt > loan_amnt) %>% 
  nrow()

#Check if funded_amnt_inv > funded_amnt => Delete if yes
pd %>% 
  filter(funded_amnt_inv > funded_amnt) %>% 
  nrow()
```
## Binary encoding (Variables have only 2 values)
```{r}
#term
train_pd <- train_pd %>%
  mutate(term = ifelse(term == "36 months", 0, 1))
test_pd <- test_pd %>%
  mutate(term = ifelse(term == "36 months", 0, 1))

#pymnt_plan
train_pd <- train_pd %>%
  mutate(pymnt_plan = ifelse(pymnt_plan == "n", 0, 1))
test_pd <- test_pd %>%
  mutate(pymnt_plan = ifelse(pymnt_plan == "n", 0, 1))

#initial_list_status
train_pd <- train_pd %>%
  mutate(initial_list_status = ifelse(initial_list_status == "w", 0, 1))
test_pd <- test_pd %>%
  mutate(initial_list_status = ifelse(initial_list_status == "w", 0, 1))

#application_type
train_pd <- train_pd %>%
  mutate(application_type = ifelse(application_type == "Individual", 0, 1))
test_pd <- test_pd %>%
  mutate(application_type = ifelse(application_type == "Individual", 0, 1))

#disbursement_method
train_pd <- train_pd %>%
  mutate(disbursement_method = ifelse(disbursement_method == "Cash", 0, 1))
test_pd <- test_pd %>%
  mutate(disbursement_method = ifelse(disbursement_method == "Cash", 0, 1))
```
## Label encoding (Ordinal variables with many categories)
```{r}
library(dplyr)

#grade
train_pd <- train_pd %>% 
  mutate(grade = case_when(
    grade == "A" ~ 1,
    grade == "B" ~ 2,
    grade == "C" ~ 3,
    grade == "D" ~ 4,
    grade == "E" ~ 5,
    grade == "F" ~ 6,
    grade == "G" ~ 7
  ))

#subgrade
subgrade_levels <- c(
  "A1", "A2", "A3", "A4", "A5",
  "B1", "B2", "B3", "B4", "B5",
  "C1", "C2", "C3", "C4", "C5",
  "D1", "D2", "D3", "D4", "D5",
  "E1", "E2", "E3", "E4", "E5",
  "F1", "F2", "F3", "F4", "F5",
  "G1", "G2", "G3", "G4", "G5"
)

train_pd <- train_pd %>% 
  mutate(sub_grade = as.numeric(factor(sub_grade, levels = subgrade_levels)))

#emp_length
train_pd <- train_pd %>%
  mutate(emp_length = case_when(
    emp_length == "< 1 year" ~ 0,
    emp_length == "1 year"   ~ 1,
    emp_length == "2 years"  ~ 2,
    emp_length == "3 years"  ~ 3,
    emp_length == "4 years"  ~ 4,
    emp_length == "5 years"  ~ 5,
    emp_length == "6 years"  ~ 6,
    emp_length == "7 years"  ~ 7,
    emp_length == "8 years"  ~ 8,
    emp_length == "9 years"  ~ 9,
    emp_length == "10+ years" ~ 10,
    TRUE ~ NA_real_
  ))

```
```{r}
library(dplyr)

#grade
test_pd <- test_pd %>% 
  mutate(grade = case_when(
    grade == "A" ~ 1,
    grade == "B" ~ 2,
    grade == "C" ~ 3,
    grade == "D" ~ 4,
    grade == "E" ~ 5,
    grade == "F" ~ 6,
    grade == "G" ~ 7
  ))

#subgrade
test_pd <- test_pd %>% 
  mutate(sub_grade = as.numeric(factor(sub_grade, levels = subgrade_levels)))

#emp_length
test_pd <- test_pd %>%
  mutate(emp_length = case_when(
    emp_length == "< 1 year" ~ 0,
    emp_length == "1 year"   ~ 1,
    emp_length == "2 years"  ~ 2,
    emp_length == "3 years"  ~ 3,
    emp_length == "4 years"  ~ 4,
    emp_length == "5 years"  ~ 5,
    emp_length == "6 years"  ~ 6,
    emp_length == "7 years"  ~ 7,
    emp_length == "8 years"  ~ 8,
    emp_length == "9 years"  ~ 9,
    emp_length == "10+ years" ~ 10,
    TRUE ~ NA_real_
  ))

```
## One-hot encoding (Nominal variables with fewer categories)
```{r}
library(dplyr)
library(fastDummies)

train_pd <- train_pd %>%
  mutate(region = case_when(
    addr_state %in% c("CT", "ME", "MA", "NH", "RI", "VT", "NJ", "NY", "PA") ~ "Northeast",
    addr_state %in% c("IL", "IN", "MI", "OH", "WI", "IA", "KS", "MN", "MO", "NE", "ND", "SD") ~ "Midwest",
    addr_state %in% c("DE", "FL", "GA", "MD", "NC", "SC", "VA", "WV", "DC",
                      "AL", "KY", "MS", "TN", "AR", "LA", "OK", "TX") ~ "South",
    addr_state %in% c("AZ", "CO", "ID", "MT", "NV", "NM", "UT", "WY",
                      "AK", "CA", "HI", "OR", "WA") ~ "West",
    TRUE ~ "Unknown"
  ))

# Encode home_ownership
if("home_ownership" %in% names(train_pd)) {
  cat("Encoding: home_ownership\n")
  train_pd <- dummy_cols(train_pd, select_columns = "home_ownership",
                   remove_first_dummy = TRUE, remove_selected_columns = TRUE)
}

# Encode verification_status
if("verification_status" %in% names(train_pd)) {
  cat("Encoding: verification_status\n")
  train_pd <- dummy_cols(train_pd, select_columns = "verification_status",
                   remove_first_dummy = TRUE, remove_selected_columns = TRUE)
}

# Encode purpose
if("purpose" %in% names(train_pd)) {
  cat("Encoding: purpose\n")
  train_pd <- dummy_cols(train_pd, select_columns = "purpose",
                   remove_first_dummy = TRUE, remove_selected_columns = TRUE)
}

# Encode region
if("region" %in% names(train_pd)) {
  cat("Encoding: region\n")
  train_pd <- dummy_cols(train_pd, select_columns = "region",
                   remove_first_dummy = TRUE, remove_selected_columns = TRUE)
}

# Delete addr_state
if("addr_state" %in% names(train_pd)) {
  train_pd <- train_pd %>% select(-addr_state)
}
```
```{r}
library(dplyr)
library(fastDummies)

test_pd <- test_pd %>%
  mutate(region = case_when(
    addr_state %in% c("CT", "ME", "MA", "NH", "RI", "VT", "NJ", "NY", "PA") ~ "Northeast",
    addr_state %in% c("IL", "IN", "MI", "OH", "WI", "IA", "KS", "MN", "MO", "NE", "ND", "SD") ~ "Midwest",
    addr_state %in% c("DE", "FL", "GA", "MD", "NC", "SC", "VA", "WV", "DC",
                      "AL", "KY", "MS", "TN", "AR", "LA", "OK", "TX") ~ "South",
    addr_state %in% c("AZ", "CO", "ID", "MT", "NV", "NM", "UT", "WY",
                      "AK", "CA", "HI", "OR", "WA") ~ "West",
    TRUE ~ "Unknown"
  ))

# Encode home_ownership
if("home_ownership" %in% names(test_pd)) {
  cat("Encoding: home_ownership\n")
  test_pd <- dummy_cols(test_pd, select_columns = "home_ownership",
                   remove_first_dummy = TRUE, remove_selected_columns = TRUE)
}

# Encode verification_status
if("verification_status" %in% names(test_pd)) {
  cat("Encoding: verification_status\n")
  test_pd <- dummy_cols(test_pd, select_columns = "verification_status",
                   remove_first_dummy = TRUE, remove_selected_columns = TRUE)
}

# Encode purpose
if("purpose" %in% names(test_pd)) {
  cat("Encoding: purpose\n")
  test_pd <- dummy_cols(test_pd, select_columns = "purpose",
                   remove_first_dummy = TRUE, remove_selected_columns = TRUE)
}

# Encode region
if("region" %in% names(test_pd)) {
  cat("Encoding: region\n")
  test_pd <- dummy_cols(test_pd, select_columns = "region",
                   remove_first_dummy = TRUE, remove_selected_columns = TRUE)
}

# Delete addr_state
if("addr_state" %in% names(test_pd)) {
  test_pd <- test_pd %>% select(-addr_state)
}
```
## Time variables processing (Month - Year format)
```{r}
library(dplyr)

train_pd <- train_pd %>%
  mutate(
    # Convert date strings to Date objects
    issue_date = as.Date(paste0("01-", issue_d), format = "%d-%b-%Y"),
    earliest_cr_date = as.Date(paste0("01-", earliest_cr_line), format = "%d-%b-%Y"),
    last_credit_pull_date = as.Date(paste0("01-", last_credit_pull_d), format = "%d-%b-%Y"),
    
    # Extract date components (vectorized operations)
    issue_year = as.integer(format(issue_date, "%Y")),
    issue_month = as.integer(format(issue_date, "%m")),
    issue_quarter = (as.integer(format(issue_date, "%m")) - 1) %/% 3 + 1,
    
    earliest_cr_year = as.integer(format(earliest_cr_date, "%Y")),
    last_credit_pull_year = as.integer(format(last_credit_pull_date, "%Y")),
    last_credit_pull_month = as.integer(format(last_credit_pull_date, "%m")),
    
    # Time differences (calculated once for reuse)
    days_issue_to_earliest = as.numeric(issue_date - earliest_cr_date),
    days_credit_pull_to_issue = as.numeric(issue_date - last_credit_pull_date),
    days_issue_to_credit_pull = as.numeric(last_credit_pull_date - issue_date),
    
    # Derived features
    credit_history_months = days_issue_to_earliest / 30,
    credit_history_years = days_issue_to_earliest / 365,
    credit_age_at_origination = days_issue_to_earliest / 365,
    
    months_from_issue_to_credit_pull = days_issue_to_credit_pull / 30,
    days_from_credit_pull_to_issue = days_credit_pull_to_issue,
    
    term_months = as.numeric(gsub(" months", "", term)),
    
    # Economic cycle indicators
    issued_during_crisis = as.integer(issue_year >= 2007 & issue_year <= 2009),
    issued_during_recovery = as.integer(issue_year >= 2010 & issue_year <= 2012),
    issued_during_early_expansion = as.integer(issue_year >= 2013 & issue_year <= 2015),
    issued_during_late_expansion = as.integer(issue_year >= 2016 & issue_year <= 2018),
    
    # Seasonality
    issue_season = c("Winter", "Spring", "Summer", "Fall")[
      findInterval(issue_month, c(1, 4, 7, 10, 13))
    ],
    
    # Credit history category
    credit_history_category = cut(
      credit_history_years,
      breaks = c(-Inf, 3, 5, 10, 20, Inf),
      labels = FALSE,
      right = FALSE
    ) - 1
  ) %>%
  # Remove intermediate calculation columns
  select(-days_issue_to_earliest, -days_credit_pull_to_issue, -days_issue_to_credit_pull)

# CRITICAL: Define reference_date AFTER creating features
# Use max issue_date from ORIGINAL data (before removing issue_date)
reference_date <- max(train_pd$issue_date, na.rm = TRUE)
cat("Reference date for temporal features:", as.character(reference_date), "\n")

# Add reference-date dependent features
train_pd <- train_pd %>%
  mutate(
    months_since_last_credit_pull = as.numeric(reference_date - last_credit_pull_date) / 30,
    
    # Credit pull recency category
    credit_pull_recency = cut(
      months_since_last_credit_pull,
      breaks = c(-Inf, 3, 6, 12, Inf),
      labels = FALSE,
      right = FALSE
    ) - 1
  )

# Create dummy variables using model.matrix
season_dummies <- model.matrix(~ issue_season - 1, data = train_pd)
colnames(season_dummies) <- gsub("issue_season", "issue_season_", colnames(season_dummies))

# Remove first dummy and add to dataframe
train_pd <- cbind(train_pd, season_dummies[, -1, drop = FALSE])

# Final cleanup
train_pd <- train_pd %>%
  select(-issue_d, -earliest_cr_line, -last_credit_pull_d,
         -issue_date, -earliest_cr_date, -last_credit_pull_date, -issue_season)

# Save reference_date for test set
saveRDS(reference_date, "reference_date.rds")

cat("Train processing complete. Columns:", ncol(train_pd), "\n")

```
```{r}
library(dplyr)

# Load reference date from training
reference_date <- readRDS("reference_date.rds")
cat("Using reference date:", as.character(reference_date), "\n")

# PRE-CALCULATE constants outside mutate
ref_date_numeric <- as.numeric(reference_date)

# OPTIMIZATION 1: Parse dates once, extract all info at once
issue_dates <- as.Date(paste0("01-", test_pd$issue_d), format = "%d-%b-%Y")
earliest_cr_dates <- as.Date(paste0("01-", test_pd$earliest_cr_line), format = "%d-%b-%Y")
last_credit_pull_dates <- as.Date(paste0("01-", test_pd$last_credit_pull_d), format = "%d-%b-%Y")

# OPTIMIZATION 2: Extract date components using fast base R functions
issue_year <- as.integer(substr(test_pd$issue_d, 5, 8))
issue_month_char <- substr(test_pd$issue_d, 1, 3)
# Fast month lookup
month_lookup <- c(Jan=1, Feb=2, Mar=3, Apr=4, May=5, Jun=6, 
                  Jul=7, Aug=8, Sep=9, Oct=10, Nov=11, Dec=12)
issue_month <- month_lookup[issue_month_char]

# OPTIMIZATION 3: Calculate date differences in bulk
days_issue_to_earliest <- as.numeric(issue_dates - earliest_cr_dates)
days_credit_pull_to_issue <- as.numeric(issue_dates - last_credit_pull_dates)
days_ref_to_credit_pull <- as.numeric(reference_date - last_credit_pull_dates)

# OPTIMIZATION 4: Vectorized calculations
credit_history_years <- days_issue_to_earliest / 365
issue_quarter <- (issue_month - 1) %/% 3 + 1

# OPTIMIZATION 5: Fast binning using findInterval (faster than cut)
credit_history_breaks <- c(-Inf, 3, 5, 10, 20, Inf)
credit_pull_breaks <- c(-Inf, 3, 6, 12, Inf)

credit_history_category <- findInterval(credit_history_years, credit_history_breaks[-1]) - 1
credit_pull_recency <- findInterval(days_ref_to_credit_pull / 30, credit_pull_breaks[-1]) - 1

# OPTIMIZATION 6: Fast season assignment
issue_season_idx <- findInterval(issue_month, c(1, 4, 7, 10, 13))
season_names <- c("Winter", "Spring", "Summer", "Fall")

# OPTIMIZATION 7: Create dummy variables directly (faster than model.matrix)
is_spring <- as.integer(issue_season_idx == 2)
is_summer <- as.integer(issue_season_idx == 3)
is_winter <- as.integer(issue_season_idx == 4)

# OPTIMIZATION 8: Single mutate with pre-calculated values
test_pd <- test_pd %>%
  mutate(
    # Date features (pre-calculated)
    issue_year = issue_year,
    issue_month = issue_month,
    issue_quarter = issue_quarter,
    
    earliest_cr_year = as.integer(format(earliest_cr_dates, "%Y")),
    last_credit_pull_year = as.integer(format(last_credit_pull_dates, "%Y")),
    last_credit_pull_month = as.integer(format(last_credit_pull_dates, "%m")),
    
    # Time-based features (pre-calculated)
    credit_history_months = days_issue_to_earliest / 30,
    credit_history_years = credit_history_years,
    credit_age_at_origination = credit_history_years,
    
    months_from_issue_to_credit_pull = -days_credit_pull_to_issue / 30,
    months_since_last_credit_pull = days_ref_to_credit_pull / 30,
    days_from_credit_pull_to_issue = days_credit_pull_to_issue,
    
    # Term extraction (vectorized gsub)
    term_months = as.numeric(gsub(" months", "", term, fixed = TRUE)),
    
    # Economic cycle (vectorized comparisons)
    issued_during_crisis = as.integer(issue_year >= 2007 & issue_year <= 2009),
    issued_during_recovery = as.integer(issue_year >= 2010 & issue_year <= 2012),
    issued_during_early_expansion = as.integer(issue_year >= 2013 & issue_year <= 2015),
    issued_during_late_expansion = as.integer(issue_year >= 2016 & issue_year <= 2018),
    
    # Categories (pre-calculated)
    credit_pull_recency = credit_pull_recency,
    credit_history_category = credit_history_category,
    
    # Season dummies (pre-calculated)
    issue_season_Spring = is_spring,
    issue_season_Summer = is_summer,
    issue_season_Winter = is_winter
  ) %>%
  # Remove original date columns
  select(-issue_d, -earliest_cr_line, -last_credit_pull_d)

cat("Test processing complete. Columns:", ncol(test_pd), "\n")

```
## "Month since" variables processing
```{r}
library(dplyr)

# OPTIMIZATION: Combine all operations into ONE mutate call
train_pd <- train_pd %>%
  mutate(
    # Recency categories for bankcard
    recent_bc_category = case_when(
      mths_since_recent_bc == 999 ~ 0,  # Never
      mths_since_recent_bc == 0 ~ 7,                                  # Current Month
      mths_since_recent_bc <= 6 ~ 6,                                  # Recent (0-6m)
      mths_since_recent_bc <= 12 ~ 5,                                 # Moderate (6-12m)
      mths_since_recent_bc <= 24 ~ 4,                                 # Old (1-2y)
      mths_since_recent_bc <= 60 ~ 3,                                 # Very Old (2-5y)
      mths_since_recent_bc <= 120 ~ 2,                                # Extremely Old (5-10y)
      mths_since_recent_bc > 120 ~ 1,                                 # Ancient (10+y)
      TRUE ~ NA_real_
    ),
    
    # Delinquency recency
    recent_delq_category = case_when(
      mths_since_recent_bc_dlq == 999 ~ 0,  # No Delinquency
      mths_since_recent_bc_dlq == 0 ~ 7,                                      # Current Delinquency
      mths_since_recent_bc_dlq <= 6 ~ 6,                                      # Very Recent Delq (0-6m)
      mths_since_recent_bc_dlq <= 12 ~ 5,                                     # Recent Delq (6-12m)
      mths_since_recent_bc_dlq <= 24 ~ 4,                                     # Medium Delq (1-2y)
      mths_since_recent_bc_dlq <= 36 ~ 3,                                     # Old Delq (2-3y)
      mths_since_recent_bc_dlq <= 60 ~ 2,                                     # Very Old Delq (3-5y)
      mths_since_recent_bc_dlq > 60 ~ 1,                                      # Ancient Delq (5+y)
      TRUE ~ NA_real_
    ),
    
    # Revolving delinquency recency
    revol_delq_category = case_when(
      mths_since_recent_revol_delinq == 999 ~ 0,  # No Revol Delq
      mths_since_recent_revol_delinq == 0 ~ 7,                                            # Current
      mths_since_recent_revol_delinq <= 6 ~ 6,                                            # Very Recent
      mths_since_recent_revol_delinq <= 12 ~ 5,                                           # Recent
      mths_since_recent_revol_delinq <= 24 ~ 4,                                           # Medium
      mths_since_recent_revol_delinq <= 36 ~ 3,                                           # Old
      mths_since_recent_revol_delinq <= 60 ~ 2,                                           # Very Old
      mths_since_recent_revol_delinq > 60 ~ 1,                                            # Ancient
      TRUE ~ NA_real_
    ),
    
    # Inquiry recency
    inquiry_recency_category = case_when(
      mths_since_recent_inq == 999 ~ 0,  # No Inquiry
      mths_since_recent_inq == 0 ~ 7,                                    # Current Month
      mths_since_recent_inq <= 3 ~ 6,                                    # Very Recent (0-3m)
      mths_since_recent_inq <= 6 ~ 5,                                    # Recent (3-6m)
      mths_since_recent_inq <= 12 ~ 4,                                   # Moderate (6-12m)
      mths_since_recent_inq <= 24 ~ 3,                                   # Old (1-2y)
      mths_since_recent_inq <= 36 ~ 2,                                   # Very Old (2-3y)
      mths_since_recent_inq > 36 ~ 1,                                    # Ancient (3+y)
      TRUE ~ NA_real_
    ),
    
    # Installment account age
    il_account_age_category = case_when(
      mo_sin_old_il_acct == 999 ~ 0,  # No Installment Account
      mo_sin_old_il_acct <= 12 ~ 6,                                # Very New (<1y)
      mo_sin_old_il_acct <= 24 ~ 5,                                # New (1-2y)
      mo_sin_old_il_acct <= 60 ~ 4,                                # Medium (2-5y)
      mo_sin_old_il_acct <= 120 ~ 3,                               # Mature (5-10y)
      mo_sin_old_il_acct <= 240 ~ 2,                               # Very Mature (10-20y)
      mo_sin_old_il_acct > 240 ~ 1,                                # Extremely Mature (20+y)
      TRUE ~ NA_real_
    ),
    
    # Revolving account age
    rev_account_age_category = case_when(
      mo_sin_old_rev_tl_op == 999 ~ 0,  # No Revolving Account
      mo_sin_old_rev_tl_op <= 12 ~ 6,                                  # Very New (<1y)
      mo_sin_old_rev_tl_op <= 24 ~ 5,                                  # New (1-2y)
      mo_sin_old_rev_tl_op <= 60 ~ 4,                                  # Medium (2-5y)
      mo_sin_old_rev_tl_op <= 120 ~ 3,                                 # Mature (5-10y)
      mo_sin_old_rev_tl_op <= 240 ~ 2,                                 # Very Mature (10-20y)
      mo_sin_old_rev_tl_op > 240 ~ 1,                                  # Extremely Mature (20+y)
      TRUE ~ NA_real_
    ),
    
    # Recent account recency
    recent_account_category = case_when(
      mo_sin_rcnt_tl == 999 ~ 0,  # No Recent Account
      mo_sin_rcnt_tl == 0 ~ 7,                             # Current Month
      mo_sin_rcnt_tl <= 6 ~ 6,                             # Very Recent (0-6m)
      mo_sin_rcnt_tl <= 12 ~ 5,                            # Recent (6-12m)
      mo_sin_rcnt_tl <= 24 ~ 4,                            # Medium (1-2y)
      mo_sin_rcnt_tl <= 60 ~ 3,                            # Old (2-5y)
      mo_sin_rcnt_tl <= 120 ~ 2,                           # Very Old (5-10y)
      mo_sin_rcnt_tl > 120 ~ 1,                            # Ancient (10+y)
      TRUE ~ NA_real_
    ),
    
    # Recent revolving account recency
    recent_rev_account_category = case_when(
      mo_sin_rcnt_rev_tl_op == 999 ~ 0,  # No Recent Rev Account
      mo_sin_rcnt_rev_tl_op == 0 ~ 7,                                    # Current Month
      mo_sin_rcnt_rev_tl_op <= 6 ~ 6,                                    # Very Recent (0-6m)
      mo_sin_rcnt_rev_tl_op <= 12 ~ 5,                                   # Recent (6-12m)
      mo_sin_rcnt_rev_tl_op <= 24 ~ 4,                                   # Medium (1-2y)
      mo_sin_rcnt_rev_tl_op <= 60 ~ 3,                                   # Old (2-5y)
      mo_sin_rcnt_rev_tl_op <= 120 ~ 2,                                  # Very Old (5-10y)
      mo_sin_rcnt_rev_tl_op > 120 ~ 1,                                   # Ancient (10+y)
      TRUE ~ NA_real_
    ),
    
    # Ratio features
    # Ratio: Recent activity vs old installment accounts
    account_activity_ratio = case_when(
      mo_sin_old_il_acct == 0 | mo_sin_old_il_acct == 999 ~ 0,
      TRUE ~ mo_sin_rcnt_tl / mo_sin_old_il_acct
    ),
    
    # Time since last delinquency relative to revolving account age
    delq_to_age_ratio = case_when(
      mo_sin_old_rev_tl_op == 0 | mo_sin_old_rev_tl_op == 999 ~ 1,
      mths_since_recent_revol_delinq == 999 ~ 1,  # No delinquency = ratio 1
      TRUE ~ mths_since_recent_revol_delinq / mo_sin_old_rev_tl_op
    ),
    
    # Ratio: Recent revolving activity vs old revolving accounts
    rev_account_activity_ratio = case_when(
      mo_sin_old_rev_tl_op == 0 | mo_sin_old_rev_tl_op == 999 ~ 0,
      TRUE ~ mo_sin_rcnt_rev_tl_op / mo_sin_old_rev_tl_op
    )
  )

cat("Train 'months since' processing complete. New features created.\n")

```
```{r}
library(dplyr)

# OPTIMIZATION: Combine all operations into ONE mutate call
test_pd <- test_pd %>%
  mutate(
    # Recency categories for bankcard
    recent_bc_category = case_when(
      mths_since_recent_bc == 999 ~ 0,  # Never
      mths_since_recent_bc == 0 ~ 7,                                  # Current Month
      mths_since_recent_bc <= 6 ~ 6,                                  # Recent (0-6m)
      mths_since_recent_bc <= 12 ~ 5,                                 # Moderate (6-12m)
      mths_since_recent_bc <= 24 ~ 4,                                 # Old (1-2y)
      mths_since_recent_bc <= 60 ~ 3,                                 # Very Old (2-5y)
      mths_since_recent_bc <= 120 ~ 2,                                # Extremely Old (5-10y)
      mths_since_recent_bc > 120 ~ 1,                                 # Ancient (10+y)
      TRUE ~ NA_real_
    ),
    
    # Delinquency recency
    recent_delq_category = case_when(
      mths_since_recent_bc_dlq == 999 ~ 0,  # No Delinquency
      mths_since_recent_bc_dlq == 0 ~ 7,                                      # Current Delinquency
      mths_since_recent_bc_dlq <= 6 ~ 6,                                      # Very Recent Delq (0-6m)
      mths_since_recent_bc_dlq <= 12 ~ 5,                                     # Recent Delq (6-12m)
      mths_since_recent_bc_dlq <= 24 ~ 4,                                     # Medium Delq (1-2y)
      mths_since_recent_bc_dlq <= 36 ~ 3,                                     # Old Delq (2-3y)
      mths_since_recent_bc_dlq <= 60 ~ 2,                                     # Very Old Delq (3-5y)
      mths_since_recent_bc_dlq > 60 ~ 1,                                      # Ancient Delq (5+y)
      TRUE ~ NA_real_
    ),
    
    # Revolving delinquency recency
    revol_delq_category = case_when(
      mths_since_recent_revol_delinq == 999 ~ 0,  # No Revol Delq
      mths_since_recent_revol_delinq == 0 ~ 7,                                            # Current
      mths_since_recent_revol_delinq <= 6 ~ 6,                                            # Very Recent
      mths_since_recent_revol_delinq <= 12 ~ 5,                                           # Recent
      mths_since_recent_revol_delinq <= 24 ~ 4,                                           # Medium
      mths_since_recent_revol_delinq <= 36 ~ 3,                                           # Old
      mths_since_recent_revol_delinq <= 60 ~ 2,                                           # Very Old
      mths_since_recent_revol_delinq > 60 ~ 1,                                            # Ancient
      TRUE ~ NA_real_
    ),
    
    # Inquiry recency
    inquiry_recency_category = case_when(
      mths_since_recent_inq == 999 ~ 0,  # No Inquiry
      mths_since_recent_inq == 0 ~ 7,                                    # Current Month
      mths_since_recent_inq <= 3 ~ 6,                                    # Very Recent (0-3m)
      mths_since_recent_inq <= 6 ~ 5,                                    # Recent (3-6m)
      mths_since_recent_inq <= 12 ~ 4,                                   # Moderate (6-12m)
      mths_since_recent_inq <= 24 ~ 3,                                   # Old (1-2y)
      mths_since_recent_inq <= 36 ~ 2,                                   # Very Old (2-3y)
      mths_since_recent_inq > 36 ~ 1,                                    # Ancient (3+y)
      TRUE ~ NA_real_
    ),
    
    # Installment account age
    il_account_age_category = case_when(
      mo_sin_old_il_acct == 999 ~ 0,  # No Installment Account
      mo_sin_old_il_acct <= 12 ~ 6,                                # Very New (<1y)
      mo_sin_old_il_acct <= 24 ~ 5,                                # New (1-2y)
      mo_sin_old_il_acct <= 60 ~ 4,                                # Medium (2-5y)
      mo_sin_old_il_acct <= 120 ~ 3,                               # Mature (5-10y)
      mo_sin_old_il_acct <= 240 ~ 2,                               # Very Mature (10-20y)
      mo_sin_old_il_acct > 240 ~ 1,                                # Extremely Mature (20+y)
      TRUE ~ NA_real_
    ),
    
    # Revolving account age
    rev_account_age_category = case_when(
      mo_sin_old_rev_tl_op == 999 ~ 0,  # No Revolving Account
      mo_sin_old_rev_tl_op <= 12 ~ 6,                                  # Very New (<1y)
      mo_sin_old_rev_tl_op <= 24 ~ 5,                                  # New (1-2y)
      mo_sin_old_rev_tl_op <= 60 ~ 4,                                  # Medium (2-5y)
      mo_sin_old_rev_tl_op <= 120 ~ 3,                                 # Mature (5-10y)
      mo_sin_old_rev_tl_op <= 240 ~ 2,                                 # Very Mature (10-20y)
      mo_sin_old_rev_tl_op > 240 ~ 1,                                  # Extremely Mature (20+y)
      TRUE ~ NA_real_
    ),
    
    # Recent account recency
    recent_account_category = case_when(
      mo_sin_rcnt_tl == 999 ~ 0,  # No Recent Account
      mo_sin_rcnt_tl == 0 ~ 7,                             # Current Month
      mo_sin_rcnt_tl <= 6 ~ 6,                             # Very Recent (0-6m)
      mo_sin_rcnt_tl <= 12 ~ 5,                            # Recent (6-12m)
      mo_sin_rcnt_tl <= 24 ~ 4,                            # Medium (1-2y)
      mo_sin_rcnt_tl <= 60 ~ 3,                            # Old (2-5y)
      mo_sin_rcnt_tl <= 120 ~ 2,                           # Very Old (5-10y)
      mo_sin_rcnt_tl > 120 ~ 1,                            # Ancient (10+y)
      TRUE ~ NA_real_
    ),
    
    # Recent revolving account recency
    recent_rev_account_category = case_when(
      mo_sin_rcnt_rev_tl_op == 999 ~ 0,  # No Recent Rev Account
      mo_sin_rcnt_rev_tl_op == 0 ~ 7,                                    # Current Month
      mo_sin_rcnt_rev_tl_op <= 6 ~ 6,                                    # Very Recent (0-6m)
      mo_sin_rcnt_rev_tl_op <= 12 ~ 5,                                   # Recent (6-12m)
      mo_sin_rcnt_rev_tl_op <= 24 ~ 4,                                   # Medium (1-2y)
      mo_sin_rcnt_rev_tl_op <= 60 ~ 3,                                   # Old (2-5y)
      mo_sin_rcnt_rev_tl_op <= 120 ~ 2,                                  # Very Old (5-10y)
      mo_sin_rcnt_rev_tl_op > 120 ~ 1,                                   # Ancient (10+y)
      TRUE ~ NA_real_
    ),
    
    # Ratio features
    # Ratio: Recent activity vs old installment accounts
    account_activity_ratio = case_when(
      mo_sin_old_il_acct == 0 | mo_sin_old_il_acct == 999 ~ 0,
      TRUE ~ mo_sin_rcnt_tl / mo_sin_old_il_acct
    ),
    
    # Time since last delinquency relative to revolving account age
    delq_to_age_ratio = case_when(
      mo_sin_old_rev_tl_op == 0 | mo_sin_old_rev_tl_op == 999 ~ 1,
      mths_since_recent_revol_delinq == 999 ~ 1,  # No delinquency = ratio 1
      TRUE ~ mths_since_recent_revol_delinq / mo_sin_old_rev_tl_op
    ),
    
    # Ratio: Recent revolving activity vs old revolving accounts
    rev_account_activity_ratio = case_when(
      mo_sin_old_rev_tl_op == 0 | mo_sin_old_rev_tl_op == 999 ~ 0,
      TRUE ~ mo_sin_rcnt_rev_tl_op / mo_sin_old_rev_tl_op
    )
  )

cat("Test 'months since' processing complete. New features created.\n")

```
## Feature Engineering
```{r}
library(dplyr)

create_features <- function(data) {
  
  data <- data %>%
    mutate(
      # 1. FINANCIAL RATIOS & CAPACITY (10 features)
      loan_to_income_ratio = loan_amnt / (annual_inc + 1),
      installment_to_income = (installment * 12) / (annual_inc + 1),
      monthly_income = annual_inc / 12,
      debt_service_ratio = installment / (monthly_income + 1),
      revol_bal_to_income = revol_bal / (annual_inc + 1),
      available_monthly_income = monthly_income - installment,
      available_income_ratio = available_monthly_income / (monthly_income + 1),
      credit_utilization_rate = revol_bal / (total_rev_hi_lim + 1),
      bankcard_utilization = revol_bal / (total_bc_limit + 1),
      overall_utilization = (revol_bal + total_bal_il) / (total_rev_hi_lim + total_il_high_credit_limit + 1),
      
      # 2. CREDIT BEHAVIOR INDICATORS (8 features)
      open_to_total_accounts_ratio = open_acc / (total_acc + 1),
      pct_revolving_with_balance = num_rev_tl_bal_gt_0 / (num_rev_accts + 1),
      avg_balance_per_revolving = revol_bal / (num_rev_tl_bal_gt_0 + 1),
      active_bankcard_ratio = num_actv_bc_tl / (num_bc_tl + 1),
      satisfactory_bankcard_ratio = num_bc_sats / (num_bc_tl + 1),
      credit_mix_score = (open_acc > 0) + (num_bc_tl > 0) + (num_il_tl > 0) + (mort_acc > 0),
      has_mortgage = ifelse(mort_acc > 0, 1, 0),
      new_account_rate = acc_open_past_24mths / (total_acc + 1),
      
      # 3. DELINQUENCY & RISK SCORES (9 features) - CHỈ DÙNG BIẾN TỒN TẠI
      delinquency_severity = (delinq_2yrs * 2) + (num_tl_90g_dpd_24m * 4) + (num_accts_ever_120_pd * 5),
      has_recent_delinquency = ifelse(delinq_2yrs > 0, 1, 0),
      has_severe_delinquency = ifelse(num_accts_ever_120_pd > 0, 1, 0),
      public_record_count = pub_rec + pub_rec_bankruptcies + tax_liens + collections_12_mths_ex_med,
      has_public_records = ifelse(public_record_count > 0, 1, 0),
      has_bankruptcy = ifelse(pub_rec_bankruptcies > 0, 1, 0),
      has_tax_liens = ifelse(tax_liens > 0, 1, 0),
      has_collections = ifelse(collections_12_mths_ex_med > 0, 1, 0),
      credit_risk_score = (delinquency_severity * 0.5) + (public_record_count * 0.5),
      
      # 4. INQUIRY & CREDIT SHOPPING (5 features)
      total_inquiries = inq_last_6mths + inq_fi,
      inquiry_rate_6m = inq_last_6mths / 6,
      high_inquiry_flag = ifelse(inq_last_6mths > 2, 1, 0),
      very_high_inquiry = ifelse(inq_last_6mths > 4, 1, 0),
      inquiry_to_new_accounts = inq_last_6mths / (open_acc_6m + 1),
      
      # 5. LOAN CHARACTERISTICS (6 features)
      loan_size_category = case_when(
        loan_amnt < 5000 ~ 0,
        loan_amnt < 10000 ~ 1,
        loan_amnt < 20000 ~ 2,
        loan_amnt >= 20000 ~ 3
      ),
      interest_rate_category = case_when(
        int_rate < 10 ~ 0,
        int_rate < 15 ~ 1,
        int_rate >= 15 ~ 2
      ),
      high_rate_high_amount = ifelse(int_rate > 15 & loan_amnt > 20000, 1, 0),
      # Extract term_months an toàn
      term_value = as.numeric(gsub("[^0-9]", "", term)),
      long_term_loan = ifelse(term_value == 60, 1, 0),
      interest_cost_pct = (installment * term_value - loan_amnt) / (loan_amnt + 1),
      
      # 6. INCOME CATEGORIZATION (2 features)
      income_category = case_when(
        annual_inc < 40000 ~ 0,
        annual_inc < 75000 ~ 1,
        annual_inc >= 75000 ~ 2
      ),
      high_income_verified = ifelse(annual_inc > 100000 & verification_status_Verified == 1, 1, 0),
      
      # 7. BALANCE & LIMIT RATIOS (5 features)
      available_credit = (total_rev_hi_lim + total_il_high_credit_limit) - (revol_bal + total_bal_il),
      available_credit_to_income = available_credit / (annual_inc + 1),
      installment_credit_ratio = total_bal_il / (total_il_high_credit_limit + 1),
      avg_balance_per_account = (revol_bal + total_bal_il) / (open_acc + 1),
      bankcard_credit_intensity = total_bc_limit / (annual_inc + 1),
      
      # 8. INTERACTION & COMPOSITE (5 features)
      high_dti_low_income = ifelse(dti > 25 & annual_inc < 50000, 1, 0),
      high_util_high_dti = ifelse(revol_util > 75 & dti > 20, 1, 0),
      excellent_payment_history = ifelse(pct_tl_nvr_dlq == 100 & delinq_2yrs == 0, 1, 0),
      debt_stress_score = (dti / 10) + (revol_util / 10) + (delinq_2yrs * 5),
      credit_capacity_score = (available_income_ratio * 40) + 
                             ((100 - overall_utilization) * 0.4) + 
                             (pct_tl_nvr_dlq * 0.2)
    ) %>%
    select(-term_value)
  
  return(data)
}
# Apply to both train and test set
train_pd <- create_features(train_pd)
test_pd <- create_features(test_pd)
```
```{r}
library(dplyr)

train_pd <- train_pd %>% select(-last_credit_pull_year,-last_credit_pull_month)
test_pd <- test_pd %>% select(-last_credit_pull_year,-last_credit_pull_month)
```
## Save file
```{r}
library(readr)
write_csv(train_pd, "train_pd.csv")
write_csv(test_pd, "test_pd.csv")
```
# Step 3. Train Model
We employed 2 models in our project: XGBoost (dataset with encoding) and CatBoost (dataset without encoding)
## XGBoost Model
### XG.0. Data setup
```{r}
library(readr)
train_pd <- read.csv("D:/train_pd.csv")
test_pd <- read.csv("D:/test_pd.csv")
head(train_pd)
head(test_pd)
```
### XG.1. Libraries
```{r}
library(xgboost)
library(dplyr)
library(caret)
library(pROC)
library(ROCR)
library(Matrix)
library(scorecard)
library(parallel)
library(doParallel)
library(SHAPforxgboost)
library(ParBayesianOptimization)
```
### XG.2. IV Selection and Data preparation
```{r}
# INFORMATION VALUE (IV)
# Calculate IV for all features
iv_results <- iv(dt = train_pd, 
                 y = "loan_status",           
                 x = NULL,                
                 positive = "1",          
                 order = TRUE)            

print(iv_results)

# IV < 0.02: Useless for prediction
# IV > 0.5: Suspicious (maybe overfitting)
iv_selected <- iv_results %>%
  filter(info_value >= 0.02 & info_value <= 0.5) %>%
  pull(variable)

cat("\n=== IV FEATURE SELECTION RESULTS ===\n")
cat("Original features:", ncol(train_pd) - 1, "\n")
cat("Selected features (IV >= 0.02):", length(iv_selected), "\n")
cat("Removed features:", ncol(train_pd) - 1 - length(iv_selected), "\n\n")

# Subset data với selected features
selected_features <- c(iv_selected, "loan_status")
train_iv <- train_pd %>% select(all_of(selected_features))
test_iv <- test_pd %>% select(all_of(selected_features))

# ZERO/NEAR-ZERO VARIANCE CHECK
# Calculate variance for all numeric variables (except target)
variance_check <- train_iv %>%
  select(-loan_status) %>%
  summarise(across(where(is.numeric), var, na.rm = TRUE))

# Identify variables with variance < 1e-10
near_zero_vars <- names(variance_check)[variance_check < 1e-10]

if (length(near_zero_vars) > 0) {
  cat("\n=== NEAR-ZERO VARIANCE VARIABLES ===\n")
  cat("Removing", length(near_zero_vars), "variables with near-zero variance\n")
  print(near_zero_vars)
  
  train_iv <- train_iv %>% select(-all_of(near_zero_vars))
  test_iv <- test_iv %>% select(-all_of(near_zero_vars))
} else {
  cat("\nNo near-zero variance variables found\n")
}

#BƯỚC 3: DATA PREPARATION FOR XGBOOST
cat("\n=== FINAL FEATURE SET ===\n")
cat("Total features for XGBoost:", ncol(train_iv) - 1, "\n\n")

final_features <- setdiff(names(train_iv), "loan_status")

X_train <- train_iv %>% select(-loan_status)
y_train <- train_iv$loan_status

X_test <- test_iv %>% select(-loan_status)
y_test <- test_iv$loan_status

sparse_train <- as(as.matrix(X_train), "dgCMatrix")
sparse_test <- as(as.matrix(X_test), "dgCMatrix")

dtrain <- xgb.DMatrix(data = sparse_train, label = y_train)
dtest <- xgb.DMatrix(data = sparse_test, label = y_test)

cat("DMatrix created successfully using sparse format\n")
```
### XG.3. Hyperparameter tuning (1st)
```{r}
# HYPERPARAMETER TUNING - GRID SEARCH
# Detect cores
n_cores <- detectCores() - 1  
cat("Using", n_cores, "CPU cores for parallel processing\n")

# SUBSAMPLE DATA HYPERPARAMETER TUNING
set.seed(42)
sample_size <- min(nrow(X_train), ceiling(nrow(X_train) * 0.2)) 
sample_idx <- sample(1:nrow(X_train), sample_size)

X_train_sample <- X_train[sample_idx, ]
y_train_sample <- y_train[sample_idx]

dtrain_sample <- xgb.DMatrix(
  data = as.matrix(X_train_sample),
  label = y_train_sample
)

cat("Hyperparameter tuning on", sample_size, "samples (", 
    round(sample_size/nrow(X_train)*100, 1), "% of data)\n\n")

# GRID SEARCH SPACE
learning_rates <- c(0.03, 0.05, 0.07)           
max_depths <- c(4, 5, 6)                        
lambdas <- c(0.5, 1.0, 2.0)                     
min_child_weights <- c(1, 3, 5)                 

results <- data.frame()

cat("Starting hyperparameter tuning...\n")
cat("Total combinations:", length(learning_rates) * length(max_depths) * length(lambdas), "\n\n")

# TREE_METHOD = "HIST" & NTHREAD
for (eta in learning_rates) {
  for (depth in max_depths) {
    for (lambda in lambdas) {
      
      cat(sprintf("Testing: eta=%.2f, max_depth=%d, lambda=%.1f\n", 
                  eta, depth, lambda))
      
      params <- list(
        objective = "binary:logistic",
        eval_metric = "auc",
        tree_method = "hist",           
        eta = eta,
        max_depth = depth,
        lambda = lambda,
        subsample = 0.8,
        colsample_bytree = 0.8,
        min_child_weight = 1,
        nthread = n_cores               
      )
      
      set.seed(42)
      cv_result <- xgb.cv(
        params = params,
        data = dtrain_sample,           
        nrounds = 300,                  
        nfold = 2,                      
        early_stopping_rounds = 30,     
        verbose = 0,
        print_every_n = 100
      )
      
      # Extract best results
      best_iter <- cv_result$best_iteration
      best_auc <- cv_result$evaluation_log$test_auc_mean[best_iter]
      best_auc_std <- cv_result$evaluation_log$test_auc_std[best_iter]
      
      # Store results
      results <- rbind(results, data.frame(
        eta = eta,
        max_depth = depth,
        lambda = lambda,
        best_iter = best_iter,
        auc_mean = best_auc,
        auc_std = best_auc_std
      ))
      
      cat(sprintf("  -> Best iteration: %d, AUC: %.4f (±%.4f)\n\n", 
                  best_iter, best_auc, best_auc_std))
      
      gc(verbose = FALSE)
    }
  }
}

# View results
results_sorted <- results[order(-results$auc_mean), ]
cat("\n=== TOP 5 BEST CONFIGURATIONS ===\n")
print(head(results_sorted, 5))

best_params <- results_sorted[1, ]
cat("\n=== BEST PARAMETERS ===\n")
print(best_params)

# TRAIN FINAL MODEL WITH FULL DATA
final_params <- list(
  objective = "binary:logistic",
  eval_metric = "auc",
  tree_method = "hist",               
  eta = best_params$eta,
  max_depth = best_params$max_depth,
  lambda = best_params$lambda,
  subsample = 0.8,
  colsample_bytree = 0.8,
  min_child_weight = 1,
  nthread = n_cores                  
)

cat("\nTraining final model with FULL DATA and best parameters...\n")

watchlist <- list(train = dtrain, test = dtest)
final_model <- xgb.train(
  params = final_params,
  data = dtrain,                      
  nrounds = ceiling(best_params$best_iter * 1.5),  
  watchlist = watchlist,
  early_stopping_rounds = 50,
  verbose = 1,
  print_every_n = 50
)

# Evaluate
pred_probs <- predict(final_model, dtest)
cat("\nFinal Model Performance:\n")
cat("Best iteration:", final_model$best_iteration, "\n")

# FEATURE SELECTION BY SHAP VALUES

# SUBSAMPLE CHO SHAP CALCULATION
shap_sample_size <- min(5000, nrow(X_train))  
shap_idx <- sample(1:nrow(X_train), shap_sample_size)
X_shap_sample <- X_train[shap_idx, ]

cat("Calculating SHAP on", shap_sample_size, "samples\n")

shap_values <- shap.values(
  xgb_model = final_model,
  X_train = as.matrix(X_shap_sample)
)

shap_scores <- shap_values$shap_score
shap_importance <- apply(abs(shap_scores), 2, mean)
shap_importance <- sort(shap_importance, decreasing = TRUE)

cat("\n=== TOP 20 MOST IMPORTANT FEATURES ===\n")
print(head(shap_importance, 20))

## Feature selection - using cumulative gain approach
shap_importance_df <- data.frame(
  feature = names(shap_importance),
  importance = as.numeric(shap_importance),
  stringsAsFactors = FALSE
)

shap_importance_df$cumulative_importance <- cumsum(shap_importance_df$importance)
shap_importance_df$cumulative_pct <- shap_importance_df$cumulative_importance / 
                                      sum(shap_importance_df$importance) * 100

# Find features for 90% cumulative importance
threshold_idx_90 <- which(shap_importance_df$cumulative_pct >= 90)
cat("Features needed for 90% cumulative importance:", threshold_idx_90, "\n")

# Use max of: 90% cumulative gain or top 40 features
top_n <- min(40, threshold_idx_90 + 5)  # Add small buffer
cat("Final feature count selected:", top_n, "\n\n")

selected_features <- shap_importance_df$feature[1:top_n]
selected_features <- intersect(selected_features, colnames(X_train))

cat("Selected", length(selected_features), "final features\n\n")

# Reduced datasets
X_train_selected <- X_train[, selected_features, drop = FALSE]
X_test_selected <- X_test[, selected_features, drop = FALSE]

# Save results
save(final_model, best_params, results_sorted, shap_importance, 
     selected_features, X_train_selected, X_test_selected,
     file = "xgboost_tuning_results_optimized.RData")

cat("\nResults saved to: xgboost_tuning_results_optimized.RData\n")
```
### XG.4. Hyperparameter tuning (2nd)
```{r}
# HYPERPARAMETER TUNING - BAYESIAN OPTIMIZATION
# Detect cores
n_cores <- detectCores() - 1
cat("Using", n_cores, "CPU cores for parallel processing\n")

# SUBSAMPLE DATA FOR HYPERPARAMETER TUNING
set.seed(42)
sample_size <- min(nrow(X_train_selected), ceiling(nrow(X_train_selected) * 0.2))
sample_idx <- sample(1:nrow(X_train_selected), sample_size)

X_train_sample <- X_train_selected[sample_idx, ]
y_train_sample <- y_train[sample_idx]

# DMatrix for sample
dtrain_sample <- xgb.DMatrix(
  data = as.matrix(X_train_sample),
  label = y_train_sample
)

cat("Hyperparameter tuning on", sample_size, "samples (", 
    round(sample_size/nrow(X_train_selected)*100, 1), "% of data)\n\n")

# BAYESIAN OPTIMIZATION SETUP
# Create folds for CV - Stratified sampling
set.seed(42)
n_pos <- sum(y_train_sample == 1)
n_neg <- sum(y_train_sample == 0)

pos_idx <- which(y_train_sample == 1)
neg_idx <- which(y_train_sample == 0)

fold1_pos <- sample(pos_idx, size = floor(length(pos_idx) * 0.5))
fold1_neg <- sample(neg_idx, size = floor(length(neg_idx) * 0.5))

folds <- list(
  fold1 = c(fold1_pos, fold1_neg),
  fold2 = setdiff(1:nrow(X_train_sample), c(fold1_pos, fold1_neg))
)

cat("Folds created with stratified sampling\n")
cat("Fold 1: ", length(folds$fold1), "samples (defaults:", sum(y_train_sample[folds$fold1] == 1), ")\n")
cat("Fold 2: ", length(folds$fold2), "samples (defaults:", sum(y_train_sample[folds$fold2] == 1), ")\n\n")

# OBJECTIVE FUNCTION - IMPROVED WITH SCALE_POS_WEIGHT
scoring_function <- function(eta, max_depth, min_child_weight, subsample, 
                            colsample_bytree, lambda, gamma, alpha) {
  
  # Integer parameters
  max_depth <- as.integer(max_depth)
  min_child_weight <- as.integer(min_child_weight)
  
  # Calculate scale_pos_weight to handle class imbalance
  scale_pos_weight <- sum(y_train_sample == 0) / sum(y_train_sample == 1)
  
  # Parameters 
  params <- list(
    objective = "binary:logistic",
    eval_metric = "auc",
    tree_method = "hist",
    eta = eta,
    max_depth = max_depth,
    min_child_weight = min_child_weight,
    subsample = subsample,
    colsample_bytree = colsample_bytree,
    lambda = lambda,
    gamma = gamma,
    alpha = alpha,
    scale_pos_weight = scale_pos_weight,  # CRITICAL for imbalanced data
    nthread = n_cores
  )
  
  # Cross-validation with error handling
  tryCatch({
    xgbcv <- xgb.cv(
      params = params,
      data = dtrain_sample,
      nrounds = 400,                      
      folds = folds,
      early_stopping_rounds = 40,         
      verbose = 0,
      maximize = TRUE
    )
    
    return(list(
      Score = max(xgbcv$evaluation_log$test_auc_mean),
      nrounds = xgbcv$best_iteration
    ))
    
  }, error = function(e) {
    return(list(Score = 0, nrounds = 0))
  })
}

# DEFINE SEARCH BOUNDS 
bounds <- list(
  eta = c(0.01, 0.15),                   
  max_depth = c(4L, 7L),                 
  min_child_weight = c(2L, 8L),          
  subsample = c(0.6, 0.95),              
  colsample_bytree = c(0.6, 0.95),       
  lambda = c(0.5, 5),                    
  gamma = c(0, 0.2),                     
  alpha = c(0, 0.5)                      
)

cat("\n=== STARTING BAYESIAN OPTIMIZATION ===\n")
cat("Search space dimensions:", length(bounds), "\n")
cat("Parameter ranges optimized for Credit Risk Default\n")
cat("Initial points:", length(bounds) + 2, "\n")
cat("Optimization iterations: 50 \n\n")

# CLEAN UP PARALLEL BACKEND
if (foreach::getDoParRegistered()) {
  registerDoSEQ()
}
cat("Running in sequential mode for stability\n\n")

# RUN BAYESIAN OPTIMIZATION
set.seed(42)
start_time <- Sys.time()

bayes_out <- bayesOpt(
  FUN = scoring_function,
  bounds = bounds,
  initPoints = length(bounds) + 2,
  iters.n = 50,                          
  iters.k = 1,
  parallel = FALSE,
  acq = "ei",
  eps = 0.0,
  gsPoints = 100,
  otherHalting = list(
    timeLimit = 10000,                   
    minUtility = 0.00005                 
  ),
  errorHandling = "continue",
  verbose = 1,
  plotProgress = FALSE
)

end_time <- Sys.time()
elapsed_time <- difftime(end_time, start_time, units = "mins")

cat("\n=== BAYESIAN OPTIMIZATION COMPLETED ===\n")
cat("Total time:", round(elapsed_time, 2), "minutes\n")
cat("Iterations completed:", nrow(bayes_out$scoreSummary), "\n\n")

# EXTRACT BEST PARAMETERS
cat("\n=== BAYESIAN OPTIMIZATION RESULTS ===\n")

best_params_bayes <- getBestPars(bayes_out)
cat("\nBest Parameters:\n")
print(best_params_bayes)

best_score <- max(bayes_out$scoreSummary$Score, na.rm = TRUE)
cat("\nBest AUC Score:", best_score, "\n")

cat("\n=== TOP 5 CONFIGURATIONS ===\n")
top_configs <- bayes_out$scoreSummary[order(-bayes_out$scoreSummary$Score), ]
print(head(top_configs[, c("eta", "max_depth", "min_child_weight", 
                           "subsample", "colsample_bytree", "lambda", 
                           "gamma", "alpha", "Score")], 5))

# TRAIN FINAL MODEL WITH FULL SELECTED DATA
# DMatrix with selected features
dtrain_selected <- xgb.DMatrix(
  data = as.matrix(X_train_selected),
  label = y_train
)

dtest_selected <- xgb.DMatrix(
  data = as.matrix(X_test_selected),
  label = y_test
)

# IMPROVED: Add scale_pos_weight to final params
scale_pos_weight_final <- sum(y_train == 0) / sum(y_train == 1)

final_params_round2 <- list(
  objective = "binary:logistic",
  eval_metric = "auc",
  tree_method = "hist",
  eta = best_params_bayes$eta,
  max_depth = as.integer(best_params_bayes$max_depth),
  min_child_weight = as.integer(best_params_bayes$min_child_weight),
  subsample = best_params_bayes$subsample,
  colsample_bytree = best_params_bayes$colsample_bytree,
  lambda = best_params_bayes$lambda,
  gamma = best_params_bayes$gamma,
  alpha = best_params_bayes$alpha,
  scale_pos_weight = scale_pos_weight_final,  
  nthread = n_cores
)

cat("\n=== TRAINING FINAL MODEL (ROUND 2) ===\n")
cat("Using full selected data with", ncol(X_train_selected), "features\n")
cat("Scale_pos_weight:", round(scale_pos_weight_final, 4), "\n\n")

# Get optimal nrounds from best iteration
best_idx <- which.max(bayes_out$scoreSummary$Score)
best_nrounds <- bayes_out$scoreSummary$nrounds[best_idx]

if (is.na(best_nrounds) || is.nan(best_nrounds) || best_nrounds <= 0) {
  cat("Warning: Invalid best_nrounds. Using default.\n")
  best_nrounds <- 250
}

cat("Using", best_nrounds, "rounds from CV (scaled to", ceiling(best_nrounds * 1.5), "for full data)\n\n")

watchlist <- list(train = dtrain_selected, test = dtest_selected)

start_train <- Sys.time()
final_model_round2 <- xgb.train(
  params = final_params_round2,
  data = dtrain_selected,
  nrounds = ceiling(best_nrounds * 1.5),
  watchlist = watchlist,
  early_stopping_rounds = 60,            
  verbose = 1,
  print_every_n = 50
)
end_train <- Sys.time()

pred_probs_round2 <- predict(final_model_round2, dtest_selected)

cat("\n=== FINAL MODEL PERFORMANCE (ROUND 2) ===\n")
cat("Best iteration:", final_model_round2$best_iteration, "\n")
cat("Training time:", round(difftime(end_train, start_train, units = "mins"), 2), "minutes\n")

# FEATURE SELECTION BY SHAP VALUES
cat("\n=== CALCULATING SHAP VALUES ===\n")

shap_sample_size <- min(5000, nrow(X_train_selected))
set.seed(42)
shap_idx <- sample(1:nrow(X_train_selected), shap_sample_size)
X_shap_sample <- X_train_selected[shap_idx, ]

cat("Calculating SHAP on", shap_sample_size, "samples\n")

start_shap <- Sys.time()
shap_values <- shap.values(
  xgb_model = final_model_round2,
  X_train = as.matrix(X_shap_sample)
)
end_shap <- Sys.time()

cat("SHAP calculation time:", round(difftime(end_shap, start_shap, units = "mins"), 2), "minutes\n")

shap_scores <- shap_values$shap_score
shap_importance <- apply(abs(shap_scores), 2, mean)
shap_importance <- sort(shap_importance, decreasing = TRUE)

cat("\n=== TOP 20 MOST IMPORTANT FEATURES ===\n")
print(head(shap_importance, 20))

# Cumulative importance-based feature selection
shap_df <- data.frame(
  feature = names(shap_importance),
  importance = as.numeric(shap_importance)
)
shap_df$cumsum <- cumsum(shap_df$importance)
shap_df$cumsum_pct <- shap_df$cumsum / sum(shap_df$importance) * 100

# Select features for 95% cumulative importance
idx_95 <- which(shap_df$cumsum_pct >= 95)[1]
top_n_round2 <- min(35, max(idx_95 - 5, 25))  # Dynamic selection between 25-35

selected_features_round2 <- shap_df$feature[1:top_n_round2]
selected_features_round2 <- intersect(selected_features_round2, colnames(X_train_selected))

cat("\nSelected", length(selected_features_round2), "features (cumulative importance: ~95%)\n")

X_train_selected_round2 <- X_train_selected[, selected_features_round2, drop = FALSE]
X_test_selected_round2 <- X_test_selected[, selected_features_round2, drop = FALSE]

# SAVE RESULTS
save(
  final_model_round2, 
  best_params_bayes,
  bayes_out,
  shap_importance,
  selected_features_round2, 
  X_train_selected_round2, 
  X_test_selected_round2,
  top_n_round2,
  final_params_round2,
  pred_probs_round2,
  scale_pos_weight_final,
  file = "xgboost_round2_bayesian_results.RData"
)

cat("\n=== ROUND 2 COMPLETE ===\n")
cat("Results saved to: xgboost_round2_bayesian_results.RData\n")

# SUMMARY
total_time <- difftime(Sys.time(), start_time, units = "mins")

cat("\n╔════════════════════════════════════════════════════════════╗\n")
cat("║         ROUND 2 SUMMARY (IMPROVED PARAMETERS)            ║\n")
cat("╠════════════════════════════════════════════════════════════╣\n")
cat("║ Method: Bayesian Opt (EI) + Stratified CV                ║\n")
cat("║ Key improvements:                                         ║\n")
cat("║   • scale_pos_weight for class imbalance                  ║\n")
cat("║   • Stratified k-fold (preserves class distribution)      ║\n")
cat("║   • Focused parameter bounds (based on Round 1)           ║\n")
cat("║   • Extended iterations (50) & time (5h)                  ║\n")
cat("║   • Cumulative importance-based feature selection         ║\n")
cat("║                                                           ║\n")
cat(sprintf("║ Search iterations: %-37d ║\n", nrow(bayes_out$scoreSummary)))
cat(sprintf("║ Best AUC: %-45.4f ║\n", best_score))
cat(sprintf("║ Features selected: %-39d ║\n", length(selected_features_round2)))
cat(sprintf("║ Total runtime: %-42.1f mins   ║\n", total_time))
cat("╚════════════════════════════════════════════════════════════╝\n")

```
### XG.5. Final XGBoost model evaluation
```{r}
cat("\n╔════════════════════════════════════════════════════════════╗\n")
cat("║         LOADING MODEL & GENERATING EVALUATION            ║\n")
cat("╚════════════════════════════════════════════════════════════╝\n\n")

# 1. LOAD MODEL FROM SAVED FILE
# Load Round 2 results
load("xgboost_round2_bayesian_results.RData")

cat("Model loaded from: xgboost_round2_bayesian_results.RData\n\n")

cat("Model details:\n")
cat("  - Trees:", final_model_round2$best_iteration, "\n")
cat("  - Features used:", ncol(X_test_selected_round2), "\n")
cat("  - Test samples:", nrow(X_test_selected_round2), "\n\n")

# 2. PREPARE TEST DATA & GET PREDICTIONS
cat("=== PREPARING TEST DATA ===\n\n")

# Create DMatrix
dtest_final <- xgb.DMatrix(
  data = as.matrix(X_test_selected_round2),
  label = y_test
)

# Get predictions
pred_probs_final <- predict(final_model_round2, dtest_final)

cat("Predictions generated\n")
cat("  - Min probability:", round(min(pred_probs_final), 4), "\n")
cat("  - Max probability:", round(max(pred_probs_final), 4), "\n")
cat("  - Mean probability:", round(mean(pred_probs_final), 4), "\n\n")

# 3. FIND OPTIMAL THRESHOLD (YOUDEN'S INDEX)
cat("=== THRESHOLD SELECTION ===\n\n")

# Calculate ROC curve
roc_curve <- roc(y_test, pred_probs_final, quiet = TRUE)

# Find optimal threshold using Youden's index
optimal_threshold <- coords(roc_curve, "best", ret = "threshold", 
                            best.method = "youden")$threshold

cat("Optimal threshold (Youden's Index):", round(optimal_threshold, 4), "\n")
cat("Using this threshold for binary predictions\n\n")

# Create binary predictions
pred_class <- ifelse(pred_probs_final >= optimal_threshold, 1, 0)

# 4. CONFUSION MATRIX
cat("\n╔════════════════════════════════════════════════════════════╗\n")
cat("║                 CONFUSION MATRIX                          ║\n")
cat("╚════════════════════════════════════════════════════════════╝\n\n")

# Create confusion matrix
cm <- confusionMatrix(
  data = factor(pred_class, levels = c(0, 1)),
  reference = factor(y_test, levels = c(0, 1)),
  positive = "1"
)

# Display confusion matrix
cat("                    Predicted\n")
cat("                No Default    Default\n")
cat("Actual  ─────────────────────────────────\n")
cat(sprintf("No Default  %8d        %8d\n", cm$table[1,1], cm$table[1,2]))
cat(sprintf("Default     %8d        %8d\n\n", cm$table[2,1], cm$table[2,2]))

# Extract values
tn <- cm$table[1,1]  # True Negatives
fp <- cm$table[1,2]  # False Positives
fn <- cm$table[2,1]  # False Negatives
tp <- cm$table[2,2]  # True Positives
total <- sum(cm$table)

# Detailed breakdown
cat("Detailed Breakdown:\n")
cat("─────────────────────────────────────────\n")
cat(sprintf("True Negatives (TN):   %8d (%.2f%%)\n", tn, tn/total*100))
cat(sprintf("False Positives (FP):  %8d (%.2f%%)  [Type I Error]\n", fp, fp/total*100))
cat(sprintf("False Negatives (FN):  %8d (%.2f%%)  [Type II Error]\n", fn, fn/total*100))
cat(sprintf("True Positives (TP):   %8d (%.2f%%)\n\n", tp, tp/total*100))

# 5. CLASSIFICATION METRICS
cat("\n╔════════════════════════════════════════════════════════════╗\n")
cat("║           CLASSIFICATION METRICS                          ║\n")
cat("╚════════════════════════════════════════════════════════════╝\n\n")

# Extract metrics
accuracy <- cm$overall['Accuracy']
sensitivity <- cm$byClass['Sensitivity']      # Recall / TPR
specificity <- cm$byClass['Specificity']      # TNR
precision <- cm$byClass['Precision']          # PPV
f1_score <- cm$byClass['F1']
balanced_accuracy <- cm$byClass['Balanced Accuracy']

# Calculate additional metrics
fpr <- fp / (fp + tn)                         # False Positive Rate
fnr <- fn / (fn + tp)                         # False Negative Rate
auc_score <- auc(roc_curve)

# KS Statistic
ks_stat <- max(abs(roc_curve$sensitivities - (1 - roc_curve$specificities)))

# Gini Coefficient
gini_coef <- 2 * auc_score - 1

# Brier Score (calibration)
brier_score <- mean((pred_probs_final - y_test)^2)

# Display metrics
cat(sprintf("%-30s %12.4f\n", "Accuracy:", accuracy))
cat(sprintf("%-30s %12.4f\n", "Balanced Accuracy:", balanced_accuracy))
cat(sprintf("%-30s %12.4f\n", "Sensitivity/Recall:", sensitivity))
cat(sprintf("%-30s %12.4f\n", "Specificity:", specificity))
cat(sprintf("%-30s %12.4f\n", "Precision:", precision))
cat(sprintf("%-30s %12.4f\n", "F1 Score:", f1_score))
cat(sprintf("%-30s %12.4f\n", "False Positive Rate:", fpr))
cat(sprintf("%-30s %12.4f\n\n", "False Negative Rate:", fnr))

# 6. DISCRIMINATION METRICS
cat("\n╔════════════════════════════════════════════════════════════╗\n")
cat("║            DISCRIMINATION METRICS                         ║\n")
cat("╚════════════════════════════════════════════════════════════╝\n\n")

cat(sprintf("%-30s %12.4f\n", "AUC-ROC:", auc_score))
cat(sprintf("%-30s %12.4f\n", "KS Statistic:", ks_stat))
cat(sprintf("%-30s %12.4f\n", "Gini Coefficient:", gini_coef))
cat(sprintf("%-30s %12.4f\n\n", "Brier Score:", brier_score))

# Interpretation
cat("Interpretation:\n")
cat("─────────────────────────────────────────\n")
if (auc_score > 0.8) {
  cat("AUC: Excellent (>0.80)\n")
} else if (auc_score > 0.75) {
  cat("AUC: Good (0.75-0.80)\n")
} else {
  cat("AUC: Fair (<0.75)\n")
}

if (ks_stat > 0.4) {
  cat("KS: Excellent (>0.40)\n")
} else if (ks_stat > 0.3) {
  cat("KS: Good (0.30-0.40)\n")
} else {
  cat("KS: Fair (<0.30)\n")
}

if (brier_score < 0.1) {
  cat("Brier: Excellent (<0.10)\n")
} else if (brier_score < 0.15) {
  cat("Brier: Good (0.10-0.15)\n")
} else {
  cat("Brier: Fair (>0.15)\n")
}

cat("\n")

# 7. BUSINESS METRICS FOR CREDIT RISK
cat("\n╔════════════════════════════════════════════════════════════╗\n")
cat("║         BUSINESS METRICS (CREDIT RISK)                   ║\n")
cat("╚════════════════════════════════════════════════════════════╝\n\n")

actual_default_rate <- mean(y_test)
predicted_default_rate <- mean(pred_class)
actual_default_count <- sum(y_test == 1)
bad_loans_caught <- tp
bad_loans_approved <- fn

cat("Default Rates:\n")
cat("─────────────────────────────────────────\n")
cat(sprintf("Actual default rate:         %.2f%%\n", actual_default_rate * 100))
cat(sprintf("Predicted default rate:      %.2f%%\n", predicted_default_rate * 100))
cat(sprintf("Total defaults in test set:  %d\n\n", actual_default_count))

cat("Credit Risk Impact:\n")
cat("─────────────────────────────────────────\n")
cat(sprintf("Bad loans CAUGHT:            %d (%.2f%% of defaults)\n", 
            bad_loans_caught, sensitivity * 100))
cat(sprintf("Bad loans APPROVED:          %d (%.2f%% of defaults) \n", 
            bad_loans_approved, fnr * 100))
cat(sprintf("Good loans REJECTED:         %d (%.2f%% of good customers)\n\n", 
            fp, fpr * 100))

# 8. COMPREHENSIVE METRICS SUMMARY TABLE
cat("\n╔════════════════════════════════════════════════════════════╗\n")
cat("║              METRICS SUMMARY TABLE                        ║\n")
cat("╠════════════════════════════════════════════════════════════╣\n")

metrics_df <- data.frame(
  Metric = c("AUC-ROC", "F1 Score", "Accuracy", "Precision", 
             "Recall/Sensitivity", "Specificity", "KS Statistic", 
             "Gini Coefficient", "Brier Score"),
  Value = c(auc_score, f1_score, accuracy, precision,
            sensitivity, specificity, ks_stat, gini_coef, brier_score),
  Status = c(
    ifelse(auc_score > 0.8, "Excellent", " Good"),
    ifelse(f1_score > 0.5, "Good", " Fair"),
    ifelse(accuracy > 0.75, "Good", " Fair"),
    ifelse(precision > 0.4, "Good", " Needs Improvement"),
    ifelse(sensitivity > 0.7, "Good", " Fair"),
    ifelse(specificity > 0.6, "Good", " Fair"),
    ifelse(ks_stat > 0.3, "Good", " Fair"),
    ifelse(gini_coef > 0.5, "Good", " Fair"),
    ifelse(brier_score < 0.15, "Good", " Fair")
  )
)

# Print formatted table
for (i in 1:nrow(metrics_df)) {
  cat(sprintf("║ %-28s %10.4f    %s%-15s ║\n",
              metrics_df$Metric[i], metrics_df$Value[i], 
              "", metrics_df$Status[i]))
}

cat("╚════════════════════════════════════════════════════════════╝\n\n")

# 9. PRODUCTION READINESS ASSESSMENT
cat("\n╔════════════════════════════════════════════════════════════╗\n")
cat("║         PRODUCTION READINESS ASSESSMENT                  ║\n")
cat("╚════════════════════════════════════════════════════════════╝\n\n")

readiness_checks <- list(
  "AUC-ROC > 0.80" = auc_score > 0.80,
  "KS Statistic > 0.30" = ks_stat > 0.30,
  "F1 Score > 0.40" = f1_score > 0.40,
  "Brier Score < 0.15" = brier_score < 0.15,
  "FNR < 0.40" = fnr < 0.40,
  "FPR < 0.10" = fpr < 0.10
)

passed <- sum(unlist(readiness_checks))
total_checks <- length(readiness_checks)

cat("Criteria                          Status    Value\n")
cat("───────────────────────────────────────────────────────────\n")

for (i in seq_along(readiness_checks)) {
  status <- ifelse(readiness_checks[[i]], "PASS", "FAIL")
  metric_name <- names(readiness_checks)[i]
  cat(sprintf("%-33s %s\n", metric_name, status))
}

cat("\n")
cat(sprintf("Overall: %d/%d criteria passed\n\n", passed, total_checks))

if (passed >= 5) {
  cat(" VERDICT: READY FOR PRODUCTION (with monitoring)\n")
} else if (passed >= 4) {
  cat(" VERDICT: CONDITIONAL READY (validate on holdout set)\n")
} else {
  cat(" VERDICT: NEEDS FURTHER IMPROVEMENT\n")
}

cat("\n")

# 10. SAVE EVALUATION RESULTS
evaluation_report <- list(
  confusion_matrix = cm,
  metrics = data.frame(
    metric = c("AUC", "F1", "Accuracy", "Precision", "Recall", "Specificity",
               "FPR", "FNR", "KS", "Gini", "Brier"),
    value = c(auc_score, f1_score, accuracy, precision, sensitivity, specificity,
             fpr, fnr, ks_stat, gini_coef, brier_score)
  ),
  threshold = optimal_threshold,
  business_metrics = list(
    actual_default_rate = actual_default_rate,
    predicted_default_rate = predicted_default_rate,
    bad_loans_caught = bad_loans_caught,
    bad_loans_approved = bad_loans_approved,
    good_loans_rejected = fp
  ),
  readiness_score = passed / total_checks
)

save(evaluation_report, 
     file = "xgboost_final_evaluation_report.RData")

cat("Evaluation report saved to: xgboost_final_evaluation_report.RData\n")
cat("EVALUATION COMPLETE\n\n")

```
## CATBoost Model
### CAT.0. Libraries
```{r}
library(catboost)
library(CatEncoders)
library(caret)
library(data.table)
library(DiceKriging)
library(dplyr)
library(mlr3)
library(mlr3learners)
library(mlr3extralearners)
library(mlr3tuning)
library(mlr3verse)
library(mlr3pipelines)
library(mlr3filters)
library(mlr3mbo)
library(paradox)
library(readr)
library(rgenoud)
library(shapper)
library(tidyverse)
set.seed(123)
```
```{r Data setup}
test <- read_csv("D:\\Machine Learning\\test_pd.csv")
train <- read_csv("D:\\Machine Learning\\train_pd.csv")
target <- train$loan_status
```

```{r Prepare for Catboost}
#For train
X_train <- train %>% select(-loan_status)
y_train <- train$loan_status

X_train <- X_train %>%
  mutate(across(where(is.character), as.factor))
X_train <- X_train %>%
  mutate(across(where(is.integer), as.factor))
X_train$issue_date <- as.numeric(X_train$issue_date)
X_train$earliest_cr_date <- as.numeric(X_train$earliest_cr_date)

#For test
X_test <- test %>% select(-loan_status)
y_test <- test$loan_status

X_test <- X_test %>%
  mutate(across(where(is.character), as.factor))
X_test <- X_test %>%
  mutate(across(where(is.integer), as.factor))
X_test$issue_date <- as.numeric(X_test$issue_date)
X_test$earliest_cr_date <- as.numeric(X_test$earliest_cr_date)

train_pool <- catboost.load_pool(data = X_train, label = y_train)
```
### CAT.1. Round 1
```{r Hyperparameter: Bayesian Optimization and Cross-validation tuning}
train_df <- cbind(X_train, loan_status = y_train)
train_df$loan_status <- as.factor(train_df$loan_status)

#Create task
task <- TaskClassif$new(
  id = "loan_default",
  backend = train_df,
  target = "loan_status"
)
learner <- lrn("classif.catboost", predict_type = "prob")

#Parameters set
learner$param_set$values <- list(
  loss_function_twoclass = "Logloss",
  eval_metric = "AUC",
  random_seed = 42
)

param_set <- ps(
  iterations         = p_int(lower = 50, upper = 200, tags = "train"),
  learning_rate      = p_dbl(lower = 0.01, upper = 0.2, tags = "train"),
  depth              = p_int(lower = 4, upper = 8, tags = "train"),
  l2_leaf_reg        = p_dbl(lower = 3, upper = 20, tags = "train"),
  bagging_temperature = p_dbl(lower = 0, upper = 1, tags = "train"),
  random_strength  = p_dbl(lower = 1, upper = 10) 
)

tuner <- tnr("mbo")  # Expected Improvement

#cross-validation
resampling <- rsmp("cv", folds = 3) 
#metric and terminator
measure <- msr("classif.auc")
terminator <- trm("evals", n_evals = 10) 
#tuning instance
instance <- TuningInstanceBatchSingleCrit$new(
  task = task,
  learner = learner,
  resampling = resampling,
  measure = measure,
  search_space = param_set,
  terminator = terminator
)
tuner$optimize(instance)

instance$result
```
```{r Build model for SHAP Value}
params1 <- list(
  loss_function = 'Logloss',    
  eval_metric = 'AUC',          
  iterations = 179,          
  learning_rate = 0.1893579,         
  depth = 7,                   
  l2_leaf_reg = 16.31243,
  bagging_temperature = 0.7326666,
  random_strength = 5.426128,
  random_seed = 42)
model1 <- catboost.train(
  learn_pool = train_pool,
  params = params1
)
```
```{r Feature importance}
#SHAPE values
shap_values <- catboost.get_feature_importance(
  model1,
  pool = train_pool,
  type = "ShapValues"
)
shap_values <- shap_values[, -ncol(shap_values)] 

#Feature selection
df_shap <- data.frame(
  feature = colnames(X_train),   
  mean_abs_shap = apply(abs(shap_values), 2, mean)
) %>%
  arrange(desc(mean_abs_shap)) %>%
  mutate(
    cum_sum = cumsum(mean_abs_shap),
    cum_perc = cum_sum / sum(mean_abs_shap)
  )
top_features <- df_shap %>%
  filter(cum_perc <= 0.90) %>%
  pull(feature)

X_train_sel <- X_train[, top_features, drop = FALSE]
train_sel <- train[, top_features, drop = FALSE]
train_pool_sel <- catboost.load_pool(data = X_train_sel, label = y_train)
```
### CAT.2. Round 2
```{r Hyperparameter: Bayesian Optimization and Cross-validation tuning}
train_sel <- data.frame(
  X_train_sel,
  loan_status = y_train
)
train_sel$loan_status <- as.factor(train_sel$loan_status)

#Create task
task <- TaskClassif$new(
  id = "loan_default",
  backend = train_sel,
  target = "loan_status"
)
learner <- lrn("classif.catboost", predict_type = "prob")

#Parameters set
learner$param_set$values <- list(
  loss_function_twoclass = "Logloss",
  eval_metric = "AUC",
  random_seed = 42
)

param_set <- ps(
  iterations         = p_int(lower = 150, upper = 250, tags = "train"),
  learning_rate      = p_dbl(lower = 0.15, upper = 0.25, tags = "train"),
  depth              = p_int(lower = 6, upper = 8, tags = "train"),
  l2_leaf_reg        = p_dbl(lower = 10, upper = 20, tags = "train"),
  bagging_temperature = p_dbl(lower = 0.5, upper = 1, tags = "train"),
  random_strength  = p_dbl(lower = 3, upper = 7) 
)

tuner <- tnr("mbo")  # Expected Improvement

#cross-validation
resampling <- rsmp("cv", folds = 5) 
#metric and terminator
measure <- msr("classif.auc")
terminator <- trm("evals", n_evals = 30) 
#tuning instance
instance <- TuningInstanceBatchSingleCrit$new(
  task = task,
  learner = learner,
  resampling = resampling,
  measure = measure,
  search_space = param_set,
  terminator = terminator
)
tuner$optimize(instance)

instance$result
```

```{r Build model for SHAP Value}
params2 <- list(
  loss_function = 'Logloss',    
  eval_metric = 'AUC',          
  iterations = 249,          
  learning_rate = 0.1907603,      
  depth = 8,                   
  l2_leaf_reg = 16.75619,
  bagging_temperature = 0.8588534,
  random_strength = 3.209933,
  random_seed = 42)
model2 <- catboost.train(
  learn_pool = train_pool_sel,
  params = params2
)
```
```{r Feature importance}
#SHAPE values
shap_values2 <- catboost.get_feature_importance(
  model2,
  pool = train_pool_sel,
  type = "ShapValues"
)
shap_values2 <- shap_values2[, -ncol(shap_values2)] 

shap_importance <- apply(abs(shap_values), 2, mean) %>%
  sort(decreasing = TRUE)
shap_importance

#Feature selection
feature_names <- colnames(X_train_sel)
names(shap_importance) <- feature_names
top_features2 <- names(shap_importance[shap_importance > 0.02]) 

X_train_sel2 <- X_train_sel[, top_features2, drop = FALSE]
train_sel2 <- train[, top_features2, drop = FALSE]
train_pool_sel2 <- catboost.load_pool(data = X_train_sel2, label = y_train)
```
### CAT.3. Final model
```{r}
params3 <- list(
  loss_function = 'Logloss',    
  eval_metric = 'AUC',          
  iterations = 249,          
  learning_rate = 0.1907603,      
  depth = 8,                   
  l2_leaf_reg = 16.75619,
  bagging_temperature = 0.8588534,
  random_strength = 3.209933,
  random_seed = 42)
model <- catboost.train(
  learn_pool = train_pool_sel2,
  params = params3
)
```
### CAT.4. Test inference
```{r}
X_test_sel <- X_test[, top_features2, drop = FALSE]
test_pool <- catboost.load_pool(
  data = X_test_sel,
  label = y_test
)

pred_prob <- catboost.predict(model, test_pool, prediction_type = "Probability")

head(pred_prob)
```
### CAT.5. Model evaluation
```{r}
library(pROC)
roc_obj <- roc(y_test, pred_prob)
auc(roc_obj)
```
### CAT.6. Save model
```{r}
catboost.save_model(model, "catboost_model.cbm")
model_loaded <- catboost.load_model("catboost_model.cbm")
```
### CAT.7. Model summary
```{r}
# ==============================================================
# CATBOOST PIPELINE - RESULTS SUMMARY
# ==============================================================

cat("\n")
cat("           CATBOOST PIPELINE COMPLETED SUCCESSFULLY!          \n")
cat("==============================================================\n\n")

## 1. Data Preparation Summary
cat("## Data Preparation & Feature Engineering\n")
cat("=== INITIAL DATA ===\n")
cat("Train:", nrow(train), "rows x", ncol(train), "columns\n")
cat("Test:", nrow(test), "rows x", ncol(test), "columns\n\n")

cat("Feature types:\n")
numeric_count <- sum(sapply(X_train, is.numeric))
factor_count <- sum(sapply(X_train, is.factor))
cat("  Numeric:", numeric_count, "\n")
cat("  Factor:", factor_count, "\n")
cat("  Total features:", ncol(X_train), "\n\n")

cat("Feature engineering:\n")
cat("  ✓ Character columns converted to factors\n")
cat("  ✓ Integer columns converted to factors\n")
cat("  ✓ Date columns converted to numeric\n\n")

## 2. Multi-round Feature Selection Summary
cat("## Multi-round Feature Selection\n")
cat("=== ROUND 1: Initial Feature Selection ===\n")
cat("  Initial features:", ncol(X_train), "\n")
cat("  SHAP-based selection (90% cumulative importance)\n")
cat("  Selected features:", length(top_features), "\n")
cat("  Reduction:", round((1 - length(top_features)/ncol(X_train)) * 100, 1), "%\n\n")

cat("=== ROUND 2: Refined Feature Selection ===\n")
cat("  Features from Round 1:", length(top_features), "\n")
cat("  SHAP importance threshold: > 0.02\n")
cat("  Final selected features:", length(top_features2), "\n")
cat("  Total reduction:", round((1 - length(top_features2)/ncol(X_train)) * 100, 1), "%\n\n")

## 3. Hyperparameter Tuning Summary
cat("## Bayesian Optimization Tuning\n")
cat("=== ROUND 1 TUNING ===\n")
cat("  Method: Bayesian Optimization (MBO)\n")
cat("  Cross-validation: 3-fold\n")
cat("  Evaluations: 10\n")
cat("  Best AUC:", 0.77, "\n\n")

cat("=== ROUND 2 TUNING ===\n")
cat("  Method: Bayesian Optimization (MBO)\n")
cat("  Cross-validation: 5-fold\n")
cat("  Evaluations: 30\n")
cat("  Best AUC:", auc(roc_obj), "\n\n")

## 4. Final Model Parameters
cat("### Final Model Hyperparameters:\n")
cat("  iterations:", params3$iterations, "\n")
cat("  learning_rate:", round(params3$learning_rate, 6), "\n")
cat("  depth:", params3$depth, "\n")
cat("  l2_leaf_reg:", round(params3$l2_leaf_reg, 5), "\n")
cat("  bagging_temperature:", round(params3$bagging_temperature, 6), "\n")
cat("  random_strength:", round(params3$random_strength, 6), "\n")
cat("  random_seed:", params3$random_seed, "\n\n")

## 5. Feature Importance Summary
cat("### Feature Importance Analysis\n")
cat("Total features in final model:", length(top_features2), "\n\n")

cat("Top 15 Most Important Features:\n")
cat("Rank Feature                        Importance\n")
cat("--------------------------------------------------------------\n")
top_10 <- head(shap_importance, 10)
for(i in 1:length(top_10)) {
  feature_name <- names(top_10)[i]
  importance_val <- round(top_10[i], 6)
  cat(sprintf("%-4d %-30s %-8.6f\n", i, feature_name, importance_val))
}
cat("--------------------------------------------------------------\n\n")

## 6. Model Performance Summary
cat("### Model Evaluation on Test Set\n")

# Tính các metrics
pred_binary <- ifelse(pred_prob > 0.5, 1, 0)
cm <- confusionMatrix(as.factor(pred_binary), as.factor(y_test))

accuracy <- cm$overall['Accuracy']
precision <- cm$byClass['Pos Pred Value'] 
recall <- cm$byClass['Sensitivity']
specificity <- cm$byClass['Specificity']
f1_score <- cm$byClass['F1']
auc_roc <- auc(roc_obj)
gini <- 2 * auc_roc - 1
brier_score <- mean((pred_prob - y_test)^2)

cat("Test data dimensions:\n")
cat("  X_test:", nrow(X_test_sel), "rows x", ncol(X_test_sel), "features\n\n")

cat("Prediction distribution:\n")
cat("  Predicted defaults (1):", sum(pred_binary == 1), "(", 
    round(mean(pred_binary == 1) * 100, 2), "%)\n")
cat("  Predicted non-defaults (0):", sum(pred_binary == 0), "(", 
    round(mean(pred_binary == 0) * 100, 2), "%)\n\n")

cat("Probability statistics:\n")
cat("  Min:", round(min(pred_prob), 4), "\n")
cat("  Q1:", round(quantile(pred_prob, 0.25), 4), "\n")
cat("  Median:", round(median(pred_prob), 4), "\n")
cat("  Q3:", round(quantile(pred_prob, 0.75), 4), "\n")
cat("  Max:", round(max(pred_prob), 4), "\n\n")

cat("=== MODEL PERFORMANCE SUMMARY ===\n")
cat(sprintf("Accuracy            : %.4f\n", accuracy))
cat(sprintf("Precision           : %.4f\n", precision))
cat(sprintf("Recall (Sensitivity): %.4f\n", recall))
cat(sprintf("Specificity         : %.4f\n", specificity))
cat(sprintf("F1-Score            : %.4f\n", f1_score))
cat(sprintf("AUC-ROC             : %.4f\n", auc_roc))
cat(sprintf("Gini Coefficient    : %.4f\n", gini))
cat(sprintf("Brier Score         : %.4f (lower is better)\n\n", brier_score))

## 7. Feature Insights
cat("### Feature Importance Insights\n")
cat("  Most important feature:", names(shap_importance)[1], "\n")
top3_contribution <- sum(shap_importance[1:3]) / sum(shap_importance) * 100
top10_contribution <- sum(shap_importance[1:10]) / sum(shap_importance) * 100
cat("  Top 3 contribute:", round(top3_contribution, 2), "% of total importance\n")
cat("  Top 10 contribute:", round(top10_contribution, 2), "% of total importance\n\n")

## 8. Pipeline Summary
cat("### Pipeline Architecture\n")
cat("  ✓ Round 1: Bayesian tuning + SHAP selection (90% cum importance)\n")
cat("  ✓ Round 2: Refined tuning + SHAP thresholding (> 0.02)\n")
cat("  ✓ Final: Model training on optimized feature set\n\n")

## 9. Final Summary
cat("### Final Model Stats\n")
cat("  Features used:", length(top_features2), "\n")
cat("  Training iterations:", params3$iterations, "\n")
cat("  Test AUC:", round(auc_roc, 4), "\n")
cat("  Test Accuracy:", round(accuracy, 4), "\n")
cat("  Model file: catboost_model.cbm\n\n")

if(auc_roc > 0.8) {
  cat(" Excellent performance achieved!\n")
} else if(auc_roc > 0.7) {
  cat("Good performance achieved\n")
} else if(auc_roc > 0.6) {
  cat("Moderate performance, consider feature engineering\n")
} else {
  cat("Poor performance, review pipeline\n")
}

cat("\n Ready for production deployment!\n\n")

cat("Output Files Generated:\n")
cat("  Models:\n")
cat("    - catboost_model.cbm\n")
cat("  Tuning Results:\n")
cat("    - Bayesian optimization results saved in instance object\n")
cat("  Feature Analysis:\n")
cat("    - SHAP importance values for all rounds\n")
cat("==============================================================\n")
```
